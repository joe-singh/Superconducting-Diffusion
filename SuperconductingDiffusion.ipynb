{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joe-singh/Superconducting-Diffusion/blob/main/SuperconductingDiffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Torchvision for FID"
      ],
      "metadata": {
        "id": "NaTBOnGzFZFG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9PurUhWo-_s"
      },
      "outputs": [],
      "source": [
        "!pip install torchvision\n",
        "!pip install torch-fidelity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive"
      ],
      "metadata": {
        "id": "MbDmVNRYFczY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKUOItskpMDb"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Random Seeds"
      ],
      "metadata": {
        "id": "iLkKBNwrFhFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "import scipy.stats as stats\n",
        "from scipy.signal import welch\n",
        "\n",
        "RANDOM_SEED = 35\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 0. Set random seed so only difference is the noise\n",
        "# ------------------------------------------------\n",
        "\n",
        "def set_seed(seed=1234):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    # Make CuDNN deterministic (slower but reproducible)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(RANDOM_SEED)"
      ],
      "metadata": {
        "id": "AUii7OPUpa-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Physical Timestream, visualise in histogram"
      ],
      "metadata": {
        "id": "EM1Td8G1FoXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "timestream = \"/content/drive/MyDrive/SnoopyCooldownLogs/250227_Uninsulated_Coil_TuneThrough0/250228/Timestreams/BP2_25MHz_67108864samples.csv\"\n",
        "\n",
        "x = np.loadtxt(timestream, comments=\"#\")\n",
        "x = np.asarray(x, dtype=np.float64)\n",
        "\n",
        "from scipy.signal import decimate\n",
        "\n",
        "#x = decimate(x, 10, ftype=\"fir\", zero_phase=True)\n",
        "\n",
        "#x = load_labone_scope_trace(fname)\n",
        "\n",
        "print(\"Loaded\", x.size, \"samples.\")\n",
        "print(\"Mean:\", x.mean(), \"Std:\", x.std())\n",
        "\n",
        "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
        "ax[0].hist(x, bins=40, density=True, alpha=0.6, label=\"Data\")\n",
        "\n",
        "# fit a normal distribution\n",
        "mu, sigma = x.mean(), x.std()\n",
        "xx = np.linspace(mu-4*sigma, mu+4*sigma, 400)\n",
        "ax[0].plot(xx, norm.pdf(xx, mu, sigma), 'r--', label=\"Gaussian fit\")\n",
        "\n",
        "ax[0].set_title(\"Histogram of noise samples\")\n",
        "ax[0].set_xlabel(\"Value (V)\")\n",
        "ax[0].set_ylabel(\"Probability density\")\n",
        "ax[0].legend()\n",
        "\n",
        "n = min(len(x), 10_000_000)\n",
        "rng = np.random.default_rng(RANDOM_SEED)\n",
        "xs = rng.choice(x, size=n, replace=False)\n",
        "stats.probplot(xs, dist=\"norm\", plot=ax[1])\n",
        "ax[1].set_title(\"QQ Plot vs Gaussian\")\n"
      ],
      "metadata": {
        "id": "bzPp_MbLpm-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bandpassing + Reshaping\n",
        "\n",
        "This cell filters the physical noise and adds it to digital noise. The crucial parameter $p$ that controls how much resonator noise is added is defined here, and used throughout the diffusion process later."
      ],
      "metadata": {
        "id": "4ndvJ2VCr2qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.signal import butter, sosfiltfilt, detrend\n",
        "from scipy.signal import welch\n",
        "\n",
        "fs = 25e6 # Sampling Frequency\n",
        "\n",
        "x0 = np.asarray(x, dtype=np.float64)\n",
        "\n",
        "# High-pass filter\n",
        "f_hp = 1e3   # example cutoff: 1 kHz\n",
        "sos_hp = butter(\n",
        "    N=6,\n",
        "    Wn=f_hp,\n",
        "    btype=\"highpass\",\n",
        "    fs=fs,\n",
        "    output=\"sos\"\n",
        ")\n",
        "\n",
        "# highpass\n",
        "r = sosfiltfilt(sos_hp, x0)\n",
        "\n",
        "# 1) isolate resonator band (tight!)\n",
        "f0 = 2.47794e6\n",
        "bw = 10\n",
        "f_low, f_high = f0 - bw/2, f0 + bw/2\n",
        "\n",
        "sos = butter(6, [f_low, f_high], btype=\"bandpass\", fs=fs, output=\"sos\")\n",
        "# bandpass\n",
        "r = sosfiltfilt(sos, r)\n",
        "\n",
        "# trim edges\n",
        "trim = int(0.1 * fs)\n",
        "r = r[trim:-trim]\n",
        "\n",
        "# 2) make synthetic flat background\n",
        "rng = np.random.default_rng(RANDOM_SEED)\n",
        "\n",
        "w = rng.standard_normal(len(r))\n",
        "\n",
        "\n",
        "# zero-mean + unit-variance\n",
        "r_u = (r - r.mean()) / r.std(ddof=0)\n",
        "w_u = (w - w.mean()) / w.std(ddof=0)   # ~1 already, but do it for exactness\n",
        "\n",
        "############################\n",
        "#  Noise Mixing Parameter\n",
        "############################\n",
        "\n",
        "p = 0.025 # <-- fraction of variance from the bandpassed physical signal (0..1)\n",
        "\n",
        "y = np.sqrt(1 - p) * w_u + np.sqrt(p) * r_u\n"
      ],
      "metadata": {
        "id": "_QUbreSKp0lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save engineered noise to .npy file, visualise saved noise"
      ],
      "metadata": {
        "id": "8PwvAp7VFwPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_noise(array, fname):\n",
        "  out = fname\n",
        "  array = array - array.mean()\n",
        "  array = array / (array.std() + 1e-8)\n",
        "  rng = np.random.default_rng(seed=RANDOM_SEED)\n",
        "  np.save(out, array)\n",
        "  print(\"Saved\", out)\n",
        "\n",
        "out = \"physical_noise_unitvar.npy\"\n",
        "\n",
        "# y if using the bandpassed superconducting array, x if using default array\n",
        "array_to_use = y\n",
        "\n",
        "save_noise(array_to_use, out)\n",
        "\n",
        "# Load physical noise\n",
        "phys_noise = np.load(\"physical_noise_unitvar.npy\")\n",
        "\n",
        "# Create equivalent digital noise\n",
        "dig_noise = np.random.randn(len(phys_noise))\n",
        "\n",
        "print(f\"Physical Std: {np.std(phys_noise):.4f}\")\n",
        "print(f\"Digital Std:  {np.std(dig_noise):.4f}\")\n",
        "\n",
        "# Plot histograms\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(dig_noise, bins=100, alpha=0.5, label='Digital (Ideal)', density=True, range=(-5, 5))\n",
        "plt.hist(phys_noise, bins=100, alpha=0.5, label='Physical (Resonator)', density=True, range=(-5, 5))\n",
        "plt.yscale('log') # Log scale reveals the tails!\n",
        "plt.legend()\n",
        "plt.title(\"Noise Distribution Check (Log Scale)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ICgVgaSQp6uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PSD Visualisation of Engineered Noise"
      ],
      "metadata": {
        "id": "iP2mv-HCF2jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import welch, sosfreqz\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "fs = 25e6\n",
        "\n",
        "# PSD before filtering\n",
        "f, Pxx = welch(dig_noise, fs=fs, window=\"hann\", nperseg=2**18, detrend=\"constant\", scaling=\"density\")\n",
        "\n",
        "# PSD after filtering (Normalization)\n",
        "f, Pyy = welch(phys_noise, fs=fs, window=\"hann\", nperseg=2**18, detrend=\"constant\", scaling=\"density\")\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.title('Engineered Noise, p = %.2f' % p)\n",
        "#plt.semilogy(f, Pxx, c='b',label=\"Digital\")\n",
        "plt.semilogy(f, Pyy, c='r', label='Engineered Physical')\n",
        "#plt.xlim(2.47e6, 2.48e6)\n",
        "plt.xlabel(\"Frequency [Hz]\", fontsize=15)\n",
        "plt.ylabel(\"PSD [1/Hz]\", fontsize=15)\n",
        "plt.grid(True, which=\"both\")\n",
        "plt.semilogx()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VmkO1aXx2vFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualisation of Noise in Image Format"
      ],
      "metadata": {
        "id": "zEGyiL9NF6cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "noise = np.load(\"physical_noise_unitvar.npy\")\n",
        "\n",
        "# take first 32*32 samples\n",
        "img = noise[:32*32].reshape(32, 32)\n",
        "\n",
        "dig = np.random.randn(32*32).reshape(32, 32)\n",
        "\n",
        "plt.figure(figsize=(8,3))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.title(r\"Physical, $p$ = %.2f\" % p)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(dig, cmap=\"gray\")\n",
        "plt.title(r\"Digital, $p = %.2f$\" % p)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "fft = np.fft.fftshift(np.fft.fft2(img))\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(np.log(np.abs(fft)+1e-6), cmap=\"inferno\")\n",
        "plt.title(r\"Physical log |FFT|, $p$ = %.2f\" % p)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "kd_UBxMP2YT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Diffusion With Physical Noise\n",
        "\n",
        "First initialise wandb"
      ],
      "metadata": {
        "id": "kKvHF3q-2V1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get('WANDB_API_KEY')\n",
        "wandb.login(key=api_key)"
      ],
      "metadata": {
        "id": "jZNGs0Fop_Bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cell below contains a full diffusion pipeline using HuggingFace's Diffusers package. It has the option to run CIFAR-10 and CelebA.\n",
        "\n",
        "The USE_PHYSICAL flag controls if physical noise is used or not. The key parameter is the value $p$ set in the noise bandpassing file above.\n",
        "\n",
        "Config parameters like number of epochs, number of inference steps, LR schedule etc. are at the config dictionary at the bottom of this cell"
      ],
      "metadata": {
        "id": "b52aYpmSGJtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import shutil\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10, CelebA\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from diffusers import UNet2DModel, DDPMScheduler\n",
        "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
        "from diffusers.training_utils import EMAModel\n",
        "from accelerate import Accelerator\n",
        "\n",
        "from PIL import Image\n",
        "from torch_fidelity import calculate_metrics\n",
        "\n",
        "##############################\n",
        "#          Params\n",
        "##############################\n",
        "\n",
        "USE_PHYSICAL = True\n",
        "tag = \"physical\" if USE_PHYSICAL else \"digital\"\n",
        "\n",
        "\n",
        "#dataset = \"celeba64\"\n",
        "dataset = \"cifar10\"\n",
        "data_path = \"./data\" if dataset == \"celeba64\" else \"./cifar10_data\"\n",
        "image_size = 64 if dataset == \"celeba64\" else 32\n",
        "inference_steps = 10 if dataset == \"celeba64\" else 50\n",
        "\n",
        "run_name = f\"run1_diffusers_{dataset}_{tag}_raw_noise_seed_{RANDOM_SEED}\"\n",
        "\n",
        "if USE_PHYSICAL:\n",
        "  run_name += f\"_p_{p}\"\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 0) Reproducibility\n",
        "# --------------------------\n",
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "# ------------------------------------\n",
        "# 1) Physical noise RNG and normaliser\n",
        "# ------------------------------------\n",
        "class PhysicalNoiseRNG:\n",
        "    def __init__(self, path: str, device: str = \"cuda\", seed: int = RANDOM_SEED):\n",
        "        noise = np.load(path).astype(np.float32)\n",
        "        self.noise = torch.from_numpy(noise).to(device)\n",
        "        self.N = self.noise.numel()\n",
        "        self.device = device\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "\n",
        "    def get(self, shape):\n",
        "        num = int(torch.tensor(shape).prod().item())\n",
        "\n",
        "        if num > self.N:\n",
        "            raise ValueError(f\"Requested {num} samples, but noise buffer has {self.N}.\")\n",
        "\n",
        "        # Random contiguous window, preserve ordering\n",
        "        start = int(self.rng.integers(0, self.N - num + 1))\n",
        "        out = self.noise[start:start + num]\n",
        "\n",
        "        return out.view(shape)\n",
        "\n",
        "\"\"\"\n",
        "def local_unit_normalize(x: torch.Tensor, eps: float = 1e-6):\n",
        "\n",
        "  Normalize each sample in a batch independently to mean 0, std 1.\n",
        "  x: [B,C,H,W]\n",
        "\n",
        "  dims = (1, 2, 3)\n",
        "  x = x - x.mean(dim=dims, keepdim=True)\n",
        "  x = x / (x.std(dim=dims, keepdim=True) + eps)\n",
        "  return x\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 2) Dataset: images only\n",
        "# --------------------------\n",
        "class CIFAR10ImagesOnly(CIFAR10):\n",
        "    def __getitem__(self, index):\n",
        "        img, _ = super().__getitem__(index)\n",
        "        return img\n",
        "\n",
        "class CelebAImagesOnly(CelebA):\n",
        "    def __getitem__(self, index):\n",
        "        img, _ = super().__getitem__(index)  # CelebA returns (PIL, target)\n",
        "        return img\n",
        "\n",
        "# CelebA ref directory\n",
        "\n",
        "def build_celeba_fid_ref_dir(\n",
        "    data_root: str = \"./data\",\n",
        "    out_dir: str = \"./fid_ref_celeba64_train_10k\",\n",
        "    image_size: int = 64,\n",
        "    n_images: int = 10_000,\n",
        "    batch_size: int = 128,\n",
        "    num_workers: int = 4,\n",
        "):\n",
        "    out_dir = Path(out_dir)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    tfm = transforms.Compose([\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.ToTensor(),  # [0,1]\n",
        "    ])\n",
        "\n",
        "    ds = CelebA(\n",
        "        root=data_root,\n",
        "        split=\"train\",\n",
        "        download=True,\n",
        "        transform=tfm,\n",
        "    )\n",
        "\n",
        "    subset = Subset(ds, range(min(n_images, len(ds))))\n",
        "\n",
        "    loader = DataLoader(\n",
        "        subset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    idx = 0\n",
        "    for imgs, _ in loader:\n",
        "        imgs_uint8 = (\n",
        "            imgs.clamp(0, 1)\n",
        "            .mul(255)\n",
        "            .to(torch.uint8)\n",
        "            .permute(0, 2, 3, 1)\n",
        "            .cpu()\n",
        "            .numpy()\n",
        "        )\n",
        "\n",
        "        for b in range(imgs_uint8.shape[0]):\n",
        "            Image.fromarray(imgs_uint8[b]).save(out_dir / f\"real_{idx:05d}.png\")\n",
        "            idx += 1\n",
        "            if idx >= n_images:\n",
        "                print(f\"âœ” Built CelebA FID reference at {out_dir}\")\n",
        "                return str(out_dir)\n",
        "\n",
        "    return str(out_dir)\n",
        "\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 3) Sampling (DDPM reverse)\n",
        "#    - supports phys noise init + phys noise at each step if desired\n",
        "# --------------------------\n",
        "@torch.no_grad()\n",
        "def ddpm_sample(\n",
        "    unet,\n",
        "    scheduler: DDPMScheduler,\n",
        "    device: str,\n",
        "    n_samples: int,\n",
        "    batch_size: int,\n",
        "    image_size: int,\n",
        "    inference_steps: int,\n",
        "    use_physical: bool,\n",
        "    phys_rng: PhysicalNoiseRNG | None,\n",
        "    seed: int,\n",
        "):\n",
        "    unet.eval()\n",
        "    gen = torch.Generator(device=device).manual_seed(seed)\n",
        "\n",
        "    scheduler.set_timesteps(inference_steps, device=device)\n",
        "\n",
        "    out = []\n",
        "    n_batches = (n_samples + batch_size - 1) // batch_size\n",
        "\n",
        "    for bi in tqdm(range(n_batches), desc=\"Sampling\", leave=False):\n",
        "        bsz = min(batch_size, n_samples - bi * batch_size)\n",
        "        shape = (bsz, 3, image_size, image_size)\n",
        "\n",
        "        if use_physical:\n",
        "            assert phys_rng is not None\n",
        "            x = phys_rng.get(shape)\n",
        "            # x = local_unit_normalize(x)\n",
        "        else:\n",
        "            x = torch.randn(shape, device=device, generator=gen)\n",
        "\n",
        "        # Reverse diffusion\n",
        "        for t in scheduler.timesteps:\n",
        "            t_batch = torch.full((bsz,), t, device=device, dtype=torch.long)\n",
        "            eps = unet(x, t_batch).sample\n",
        "\n",
        "            step_out = scheduler.step(eps, t, x, generator=gen)\n",
        "            x = step_out.prev_sample\n",
        "\n",
        "        out.append(x.detach().cpu())\n",
        "\n",
        "    out = torch.cat(out, dim=0)[:n_samples]\n",
        "    return out  # in [-1, 1] (because training data is normalized that way)\n",
        "\n",
        "@torch.no_grad()\n",
        "def ddpm_trajectory(\n",
        "    unet,\n",
        "    scheduler: DDPMScheduler,\n",
        "    device: str,\n",
        "    image_size: int,\n",
        "    inference_steps: int,\n",
        "    use_physical: bool,\n",
        "    phys_rng: PhysicalNoiseRNG | None,\n",
        "    seed: int,\n",
        "    n_samples: int = 4,\n",
        "    n_frames: int = 8,\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns: frames list, each element is a tensor [n_samples, 3, H, W] in [-1,1]\n",
        "    Captures n_frames snapshots across the reverse process.\n",
        "    \"\"\"\n",
        "    unet.eval()\n",
        "    gen = torch.Generator(device=device).manual_seed(seed)\n",
        "\n",
        "    scheduler.set_timesteps(inference_steps, device=device)\n",
        "    timesteps = list(scheduler.timesteps)\n",
        "\n",
        "    # choose roughly-uniform capture indices\n",
        "    capture_ids = set(np.linspace(0, len(timesteps) - 1, n_frames, dtype=int).tolist())\n",
        "\n",
        "    shape = (n_samples, 3, image_size, image_size)\n",
        "    if use_physical:\n",
        "        assert phys_rng is not None\n",
        "        x = phys_rng.get(shape)\n",
        "        # x = local_unit_normalize(x)\n",
        "    else:\n",
        "        x = torch.randn(shape, device=device, generator=gen)\n",
        "\n",
        "    frames = []\n",
        "    for idx, t in enumerate(timesteps):\n",
        "        t_batch = torch.full((n_samples,), t, device=device, dtype=torch.long)\n",
        "        eps = unet(x, t_batch).sample\n",
        "        x = scheduler.step(eps, t, x, generator=gen).prev_sample\n",
        "\n",
        "        if idx in capture_ids or idx == len(timesteps) - 1:\n",
        "            frames.append(x.detach().cpu().clone())\n",
        "\n",
        "    return frames\n",
        "\n",
        "\n",
        "\n",
        "def tensor_to_uint8_images(x):\n",
        "    \"\"\"\n",
        "    x: [N,3,H,W] in [-1,1] -> uint8 HWC in [0,255]\n",
        "    \"\"\"\n",
        "    x = (x / 2 + 0.5).clamp(0, 1)\n",
        "    x = (x * 255).to(torch.uint8)\n",
        "    x = x.permute(0, 2, 3, 1).contiguous()\n",
        "    return x\n",
        "\n",
        "\n",
        "def save_image_dir_uint8_hwc(imgs_uint8_hwc: torch.Tensor, out_dir: Path, prefix=\"gen\"):\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    n = imgs_uint8_hwc.shape[0]\n",
        "    for i in range(n):\n",
        "        Image.fromarray(imgs_uint8_hwc[i].cpu().numpy()).save(out_dir / f\"{prefix}_{i:05d}.jpg\", quality=95)\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 4) FID-only eval (torch-fidelity)\n",
        "#    - deletes generated files afterwards\n",
        "# --------------------------\n",
        "@torch.no_grad()\n",
        "def fid_eval_torch_fidelity(\n",
        "    unet,\n",
        "    scheduler,\n",
        "    device: str,\n",
        "    out_root: str,\n",
        "    epoch: int,\n",
        "    image_size: int,\n",
        "    inference_steps: int,\n",
        "    fid_ref: str = \"cifar10-train\",\n",
        "    n_samples: int = 10_000,\n",
        "    batch_size: int = 256,\n",
        "    seed: int = 0,\n",
        "    use_physical: bool = False,\n",
        "    phys_rng: PhysicalNoiseRNG | None = None,\n",
        "    cache: bool = False,              # keep False to avoid the notebook rerun cache-unpickling drama\n",
        "):\n",
        "    out_root = Path(out_root)\n",
        "    gen_dir = out_root / \"fid_tmp\" / f\"epoch_{epoch:03d}\"\n",
        "    if gen_dir.exists():\n",
        "        shutil.rmtree(gen_dir)\n",
        "\n",
        "    samples = ddpm_sample(\n",
        "        unet=unet,\n",
        "        scheduler=scheduler,\n",
        "        device=device,\n",
        "        n_samples=n_samples,\n",
        "        batch_size=batch_size,\n",
        "        image_size=image_size,\n",
        "        inference_steps=inference_steps,\n",
        "        use_physical=use_physical,\n",
        "        phys_rng=phys_rng,\n",
        "        seed=seed,\n",
        "    )\n",
        "\n",
        "    imgs_uint8 = tensor_to_uint8_images(samples)\n",
        "    save_image_dir_uint8_hwc(imgs_uint8, gen_dir, prefix=\"gen\")\n",
        "\n",
        "    # FID only\n",
        "    metrics = calculate_metrics(\n",
        "        input1=str(gen_dir),\n",
        "        input2=fid_ref,\n",
        "        cuda=torch.cuda.is_available(),\n",
        "        fid=True,\n",
        "        isc=False,\n",
        "        kid=False,\n",
        "        prc=False,\n",
        "        verbose=False,\n",
        "        cache=cache,\n",
        "    )\n",
        "    fid = float(metrics[\"frechet_inception_distance\"])\n",
        "\n",
        "    # cleanup\n",
        "    shutil.rmtree(gen_dir, ignore_errors=True)\n",
        "    return fid\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 5) Training loop (diffusers + EMA + accelerate)\n",
        "# --------------------------\n",
        "def train_diffusers_with_custom_noise(config):\n",
        "    set_seed(config[\"seed\"])\n",
        "\n",
        "    accelerator = Accelerator(\n",
        "        mixed_precision=config[\"mixed_precision\"],\n",
        "        gradient_accumulation_steps=config[\"gradient_accumulation_steps\"],\n",
        "        log_with=\"wandb\",\n",
        "        project_dir=os.path.join(config[\"output_dir\"], \"logs\"),\n",
        "    )\n",
        "\n",
        "    if accelerator.is_main_process:\n",
        "      accelerator.init_trackers(\n",
        "          project_name=config[\"wandb_project\"],\n",
        "          config=config,\n",
        "          init_kwargs={\"wandb\": {\"name\": config.get(\"wandb_run_name\", \"run\")}},\n",
        "      )\n",
        "      os.makedirs(config[\"output_dir\"], exist_ok=True)\n",
        "      os.makedirs(os.path.join(config[\"output_dir\"], \"samples\"), exist_ok=True)\n",
        "\n",
        "    # data\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.Resize((config[\"image_size\"], config[\"image_size\"])),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),  # [-1,1]\n",
        "    ])\n",
        "\n",
        "    ds = config.get(\"dataset_name\", \"cifar10\").lower()\n",
        "\n",
        "    if ds == \"cifar10\":\n",
        "        dataset = CIFAR10ImagesOnly(\n",
        "            root=config[\"dataset_path\"],\n",
        "            train=True,\n",
        "            transform=transform_train,\n",
        "            download=True,\n",
        "        )\n",
        "    elif ds in {\"celeba64\", \"celeba\"}:\n",
        "        dataset = CelebAImagesOnly(\n",
        "            root=config[\"dataset_path\"],\n",
        "            split=\"train\",\n",
        "            transform=transform_train,\n",
        "            download=True,\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown dataset_name: {config['dataset_name']}\")\n",
        "\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=config[\"train_batch_size\"],\n",
        "        shuffle=True,\n",
        "        num_workers=config[\"num_workers\"],\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "    # model: EXACT UNet settings you pasted (attention blocks etc.)\n",
        "    model = UNet2DModel(\n",
        "        sample_size=config[\"image_size\"],\n",
        "        in_channels=3,\n",
        "        out_channels=3,\n",
        "        layers_per_block=2,\n",
        "        block_out_channels=(128, 256, 512, 512),\n",
        "        down_block_types=(\n",
        "            \"DownBlock2D\",\n",
        "            \"DownBlock2D\",\n",
        "            \"DownBlock2D\",\n",
        "            \"AttnDownBlock2D\",\n",
        "        ),\n",
        "        up_block_types=(\n",
        "            \"AttnUpBlock2D\",\n",
        "            \"UpBlock2D\",\n",
        "            \"UpBlock2D\",\n",
        "            \"UpBlock2D\",\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    noise_scheduler = DDPMScheduler(\n",
        "        num_train_timesteps=config[\"num_train_timesteps\"],\n",
        "        beta_schedule=config[\"beta_schedule\"],\n",
        "        prediction_type=config[\"prediction_type\"],\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=config[\"learning_rate\"],\n",
        "        betas=(config[\"adam_beta1\"], config[\"adam_beta2\"]),\n",
        "        weight_decay=config[\"adam_weight_decay\"],\n",
        "        eps=config[\"adam_epsilon\"],\n",
        "    )\n",
        "\n",
        "    lr_scheduler = get_cosine_schedule_with_warmup(\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=config[\"lr_warmup_steps\"],\n",
        "        num_training_steps=(len(dataloader) * config[\"num_epochs\"]),\n",
        "    )\n",
        "\n",
        "    # prepare\n",
        "    model, optimizer, dataloader, lr_scheduler = accelerator.prepare(\n",
        "        model, optimizer, dataloader, lr_scheduler\n",
        "    )\n",
        "\n",
        "    # EMA (same idea as your hardcore code)\n",
        "    ema = None\n",
        "    if config.get(\"ema_decay\", 0) > 0:\n",
        "        ema = EMAModel(\n",
        "            model.parameters(),\n",
        "            decay=config[\"ema_decay\"],\n",
        "            use_ema_warmup=True,\n",
        "            inv_gamma=1.0,\n",
        "            power=3/4,\n",
        "        )\n",
        "        ema.to(accelerator.device)\n",
        "        accelerator.register_for_checkpointing(ema)\n",
        "\n",
        "    # physical RNGs (train + eval) on the right device\n",
        "    phys_rng_train = None\n",
        "    phys_rng_eval = None\n",
        "    if config[\"use_physical_noise\"]:\n",
        "        # different seeds to make the training and eval different, non correlated\n",
        "        phys_rng_train = PhysicalNoiseRNG(config[\"physical_noise_path\"],\n",
        "                                          seed=config[\"seed\"]+1,\n",
        "                                          device=str(accelerator.device))\n",
        "        phys_rng_eval = PhysicalNoiseRNG(config[\"physical_noise_path\"],\n",
        "                                         seed=config[\"seed\"]+2,\n",
        "                                         device=str(accelerator.device))\n",
        "\n",
        "    global_step = 0\n",
        "\n",
        "    for epoch in range(config[\"num_epochs\"]):\n",
        "        model.train()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        n_batches = 0\n",
        "\n",
        "        progress = tqdm(\n",
        "            dataloader,\n",
        "            disable=not accelerator.is_local_main_process,\n",
        "            desc=f\"Epoch {epoch+1}/{config['num_epochs']}\",\n",
        "        )\n",
        "\n",
        "        for batch in progress:\n",
        "            clean = batch  # [B,3,H,W] in [-1,1]\n",
        "            bsz = clean.shape[0]\n",
        "\n",
        "            # timesteps\n",
        "            timesteps = torch.randint(\n",
        "                0, noise_scheduler.config.num_train_timesteps, (bsz,),\n",
        "                device=clean.device\n",
        "            ).long()\n",
        "\n",
        "            # CUSTOM NOISE HERE:\n",
        "            if config[\"use_physical_noise\"]:\n",
        "                noise = phys_rng_train.get(clean.shape)\n",
        "                # noise = local_unit_normalize(noise) # normalise locally\n",
        "            else:\n",
        "                noise = torch.randn_like(clean)\n",
        "\n",
        "            # standard scheduler add_noise\n",
        "            noisy = noise_scheduler.add_noise(clean, noise, timesteps)\n",
        "\n",
        "            with accelerator.accumulate(model):\n",
        "                pred = model(noisy, timesteps).sample\n",
        "\n",
        "                if config[\"prediction_type\"] == \"epsilon\":\n",
        "                    target = noise\n",
        "                elif config[\"prediction_type\"] == \"v_prediction\":\n",
        "                    target = noise_scheduler.get_velocity(clean, noise, timesteps)\n",
        "                else:\n",
        "                    raise ValueError(f\"Unknown prediction_type: {config['prediction_type']}\")\n",
        "\n",
        "                loss = F.mse_loss(pred, target)\n",
        "\n",
        "                accelerator.backward(loss)\n",
        "                accelerator.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "                optimizer.step()\n",
        "                lr_scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            if accelerator.is_main_process and ema is not None:\n",
        "                ema.step(model.parameters())\n",
        "\n",
        "            running_loss += float(loss.detach().item())\n",
        "            n_batches += 1\n",
        "\n",
        "            logs = {\"loss\": float(loss.detach().item()), \"lr\": float(lr_scheduler.get_last_lr()[0])}\n",
        "            progress.set_postfix(**logs)\n",
        "            accelerator.log(logs, step=global_step)\n",
        "            global_step += 1\n",
        "\n",
        "        avg_loss = running_loss / max(1, n_batches)\n",
        "        if accelerator.is_main_process:\n",
        "          accelerator.log({\"avg_loss\": avg_loss, \"epoch\": epoch + 1}, step=global_step)\n",
        "\n",
        "        # ---- Eval / checkpoint ----\n",
        "        do_eval = (accelerator.is_main_process and (\n",
        "            (epoch + 1) % config[\"eval_epochs\"] == 0 or (epoch == 0)\n",
        "        ))\n",
        "        if do_eval:\n",
        "            # checkpoint training state\n",
        "            ckpt_dir = os.path.join(config[\"output_dir\"], f\"checkpoint-epoch-{epoch+1}\")\n",
        "            accelerator.save_state(ckpt_dir)\n",
        "\n",
        "            # swap EMA weights in for eval (then restore)\n",
        "            if ema is not None:\n",
        "                ema.store(model.parameters())\n",
        "                ema.copy_to(model.parameters())\n",
        "\n",
        "            unwrapped = accelerator.unwrap_model(model)\n",
        "\n",
        "            # quick sample grid for sanity\n",
        "            eval_steps = config[\"sample_inference_steps\"]\n",
        "            grid_n = config[\"num_save_samples\"]\n",
        "            grid = ddpm_sample(\n",
        "                unet=unwrapped,\n",
        "                scheduler=noise_scheduler,\n",
        "                device=str(accelerator.device),\n",
        "                n_samples=grid_n,\n",
        "                batch_size=min(grid_n, 64),\n",
        "                image_size=config[\"image_size\"],\n",
        "                inference_steps=eval_steps,\n",
        "                use_physical=config[\"use_physical_noise\"],\n",
        "                phys_rng=phys_rng_eval,\n",
        "                seed=config[\"seed\"] + epoch + 123,\n",
        "            )\n",
        "            grid = (grid / 2 + 0.5).clamp(0, 1)\n",
        "            grid_img = vutils.make_grid(grid, nrow=int(math.sqrt(grid_n)))\n",
        "            vutils.save_image(grid_img, os.path.join(config[\"output_dir\"], \"samples\", f\"grid_epoch{epoch+1:03d}.png\"))\n",
        "            if accelerator.is_main_process:\n",
        "              accelerator.log(\n",
        "                  {\"samples_grid\": wandb.Image(grid_img, caption=f\"Epoch {epoch+1}\")},\n",
        "                  step=global_step,\n",
        "              )\n",
        "\n",
        "            # FID(10k)\n",
        "            # fid_ref = \"cifar10-train\" if config[\"dataset_name\"] == \"cifar10\" else \"celeba-train\"\n",
        "            ###\n",
        "\n",
        "            if config[\"dataset_name\"] == \"cifar10\":\n",
        "                fid_ref = \"cifar10-train\"\n",
        "            else:\n",
        "                fid_ref_dir = os.path.join(\n",
        "                    config[\"output_dir\"],\n",
        "                    \"fid_ref_celeba64_train_10k\",\n",
        "                )\n",
        "\n",
        "                if not os.path.isdir(fid_ref_dir) or len(os.listdir(fid_ref_dir)) < 10_000:\n",
        "                    build_celeba_fid_ref_dir(\n",
        "                        data_root=config[\"dataset_path\"],  # <-- \"./data\"\n",
        "                        out_dir=fid_ref_dir,\n",
        "                        image_size=config[\"image_size\"],    # 64\n",
        "                        n_images=10_000,\n",
        "                        batch_size=128,\n",
        "                        num_workers=config[\"num_workers\"],\n",
        "                    )\n",
        "\n",
        "                fid_ref = fid_ref_dir\n",
        "\n",
        "\n",
        "            ###\n",
        "\n",
        "            fid = fid_eval_torch_fidelity(\n",
        "                unet=unwrapped,\n",
        "                scheduler=noise_scheduler,\n",
        "                device=str(accelerator.device),\n",
        "                out_root=config[\"output_dir\"],\n",
        "                epoch=epoch + 1,\n",
        "                image_size=config[\"image_size\"],\n",
        "                inference_steps=config[\"fid_inference_steps\"],\n",
        "                fid_ref=fid_ref,\n",
        "                n_samples=config[\"fid_n_generated\"],\n",
        "                batch_size=config[\"fid_gen_batch_size\"],\n",
        "                seed=config[\"seed\"] + 10_000 + epoch,\n",
        "                use_physical=config[\"use_physical_noise\"],\n",
        "                phys_rng=phys_rng_eval,\n",
        "                cache=False,  # keep it stable across notebook reruns\n",
        "            )\n",
        "\n",
        "            print(f\"[Epoch {epoch+1}] FID(10k) = {fid:.3f}\")\n",
        "            accelerator.log({\"fid10k\": fid, \"epoch\": epoch + 1}, step=global_step)\n",
        "\n",
        "            # ---- Denoising trajectory (log to W&B) ----\n",
        "            traj_frames = ddpm_trajectory(\n",
        "                unet=unwrapped,\n",
        "                scheduler=noise_scheduler,\n",
        "                device=str(accelerator.device),\n",
        "                image_size=config[\"image_size\"],\n",
        "                inference_steps=config[\"sample_inference_steps\"],  # or a separate traj_steps config\n",
        "                use_physical=config[\"use_physical_noise\"],\n",
        "                phys_rng=phys_rng_eval,\n",
        "                seed=config[\"seed\"] + 999 + epoch,\n",
        "                n_samples=1,\n",
        "                n_frames=6,\n",
        "            )\n",
        "\n",
        "            # Make one image: rows = samples, cols = time\n",
        "            # Each frame is [N,3,H,W] in [-1,1]\n",
        "            vis = []\n",
        "            for f in traj_frames:\n",
        "                f = (f / 2 + 0.5).clamp(0, 1)  # [N,3,H,W]\n",
        "                vis.append(f)\n",
        "            vis = torch.cat(vis, dim=0)  # [N*n_frames, 3, H, W]\n",
        "\n",
        "            n_frames = len(traj_frames)\n",
        "            traj_grid = vutils.make_grid(vis, nrow=n_frames)\n",
        "\n",
        "            # Save locally (optional)\n",
        "            traj_path = os.path.join(config[\"output_dir\"], \"samples\", f\"traj_epoch{epoch+1:03d}.png\")\n",
        "            vutils.save_image(traj_grid, traj_path)\n",
        "\n",
        "            # Log to W&B\n",
        "            if accelerator.is_main_process:\n",
        "                accelerator.log(\n",
        "                    {\"denoising_traj\": wandb.Image(traj_grid, caption=f\"Epoch {epoch+1} denoising trajectory\")},\n",
        "                    step=global_step,\n",
        "                )\n",
        "\n",
        "\n",
        "            # restore training weights if EMA\n",
        "            if ema is not None:\n",
        "                ema.restore(model.parameters())\n",
        "\n",
        "    # final save (EMA weights if enabled)\n",
        "    if accelerator.is_main_process:\n",
        "        if ema is not None:\n",
        "            ema.copy_to(model.parameters())\n",
        "\n",
        "        # save diffusers-style checkpoint\n",
        "        save_dir = os.path.join(config[\"output_dir\"], \"final\")\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        accelerator.unwrap_model(model).save_pretrained(save_dir)\n",
        "        noise_scheduler.save_pretrained(save_dir)\n",
        "\n",
        "    accelerator.end_training()\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 6) Example config (match your hardcore defaults)\n",
        "# --------------------------\n",
        "config = {\n",
        "    # data\n",
        "    \"dataset_name\": dataset,\n",
        "    \"dataset_path\": data_path,\n",
        "    \"image_size\": image_size,\n",
        "    \"num_workers\": 4,\n",
        "\n",
        "    # model/scheduler\n",
        "    \"num_train_timesteps\": 1000,\n",
        "    \"beta_schedule\": \"linear\",\n",
        "    \"prediction_type\": \"epsilon\",\n",
        "\n",
        "    # training\n",
        "    \"num_epochs\": 50,\n",
        "    \"train_batch_size\": 128,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"lr_warmup_steps\": 500,\n",
        "    \"adam_beta1\": 0.95,\n",
        "    \"adam_beta2\": 0.999,\n",
        "    \"adam_weight_decay\": 1e-6,\n",
        "    \"adam_epsilon\": 1e-8,\n",
        "\n",
        "    # EMA\n",
        "    \"ema_decay\": 0.9999,\n",
        "\n",
        "    # logging\n",
        "    \"mixed_precision\": \"fp16\",\n",
        "    \"wandb_project\": f\"{dataset}_diffusion_superconductor_engineered\",\n",
        "    \"wandb_run_name\": run_name,\n",
        "    \"output_dir\": \"./\" + run_name,\n",
        "\n",
        "    # physical noise\n",
        "    \"use_physical_noise\": USE_PHYSICAL,\n",
        "    \"physical_noise_path\": \"./physical_noise_unitvar.npy\",\n",
        "\n",
        "    # eval\n",
        "    \"eval_epochs\": 10,\n",
        "    \"num_save_samples\": 36,\n",
        "    \"sample_inference_steps\": inference_steps,  # for the saved sample grid\n",
        "\n",
        "    # FID\n",
        "    \"fid_n_generated\": 10_000,\n",
        "    \"fid_inference_steps\": inference_steps,     # DDPM steps for FID sampling\n",
        "    \"fid_gen_batch_size\": 256,     # can differ from training batch size\n",
        "\n",
        "    # seed\n",
        "    \"seed\": RANDOM_SEED,\n",
        "}\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_diffusers_with_custom_noise(config)\n"
      ],
      "metadata": {
        "id": "cqkvxNMFqEjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "gMm0FLmSjA5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = len(phys_noise)\n",
        "L = 3*32*32  # one noise \"image\"\n",
        "rng = np.random.default_rng(0)\n",
        "\n",
        "stds = []\n",
        "means = []\n",
        "for _ in range(2000):\n",
        "    s = rng.integers(0, N-L)\n",
        "    w = phys_noise[s:s+L]\n",
        "    means.append(w.mean())\n",
        "    stds.append(w.std())\n",
        "\n",
        "print(np.mean(stds), np.std(stds), np.min(stds), np.max(stds))\n",
        "print(np.mean(means), np.std(means), np.min(means), np.max(means))\n"
      ],
      "metadata": {
        "id": "jHwE_VTWuY1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZNgxt_LnSpkz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "authorship_tag": "ABX9TyPFMnZv3/EJ/cB3VDqRURMi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}